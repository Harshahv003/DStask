{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d8717e",
   "metadata": {},
   "source": [
    "\n",
    "# Trader Behavior vs Market Sentiment — End‑to‑End Analysis (Colab)\n",
    "\n",
    "**Objective:** Explore the relationship between trader performance and market sentiment (Fear/Greed) and derive actionable insights for trading strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f72fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Setup: installs & imports (run once) ===\n",
    "!pip -q install gdown pandas numpy matplotlib scipy scikit-learn plotly\n",
    "\n",
    "import os, math, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Folders (mirror required structure)\n",
    "ROOT = os.getcwd()\n",
    "CSV_DIR = os.path.join(ROOT, \"csv_files\")\n",
    "OUT_DIR = os.path.join(ROOT, \"outputs\")\n",
    "os.makedirs(CSV_DIR, exist_ok=True)\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Working directory:\", ROOT)\n",
    "print(\"csv_files ->\", CSV_DIR)\n",
    "print(\"outputs   ->\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ad7e5",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Data Access (Google Drive IDs)\n",
    "If the links are public, use `gdown` with the file IDs. Otherwise, mount Drive and copy files manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad3b286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update these IDs if the company shares new links\n",
    "HYPERLIQUID_FILE_ID = \"1IAfLZwu6rJzyWKgBToqwSmmVYU6VbjVs\"\n",
    "FEARGREED_FILE_ID   = \"1PgQC0tO8XN-wqkNyghWc_-mnrYv_nhSf\"\n",
    "\n",
    "# Choose preferred method: (A) direct gdown or (B) manual upload/mount\n",
    "USE_GDOWN = True\n",
    "\n",
    "hyperliquid_path = os.path.join(CSV_DIR, \"hyperliquid_raw.csv\")\n",
    "feargreed_path   = os.path.join(CSV_DIR, \"fear_greed.csv\")\n",
    "\n",
    "if USE_GDOWN:\n",
    "    import gdown\n",
    "    # Force Google Drive download by ID and save to known filenames\n",
    "    gdown.download(id=HYPERLIQUID_FILE_ID, output=hyperliquid_path, quiet=False)\n",
    "    gdown.download(id=FEARGREED_FILE_ID, output=feargreed_path, quiet=False)\n",
    "else:\n",
    "    print(\"Skipping gdown. Upload CSVs to csv_files/ named as shown above.\")\n",
    "\n",
    "print(\"Files expected:\")\n",
    "print(\" -\", hyperliquid_path, os.path.exists(hyperliquid_path))\n",
    "print(\" -\", feargreed_path, os.path.exists(feargreed_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93aade6",
   "metadata": {},
   "source": [
    "\n",
    "## 2) Robust Loaders & Cleaning\n",
    "Handles CSV/JSON/NDJSON; parses time and normalizes fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b6f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_table(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    name = os.path.basename(path).lower()\n",
    "    try:\n",
    "        if name.endswith(\".csv\"):\n",
    "            return pd.read_csv(path)\n",
    "        elif name.endswith(\".json\"):\n",
    "            return pd.read_json(path)\n",
    "        elif name.endswith(\".ndjson\") or name.endswith(\".jsonl\"):\n",
    "            return pd.read_json(path, lines=True)\n",
    "        else:\n",
    "            # Attempt CSV by default\n",
    "            return pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print(\"Primary load failed, trying different encodings...\")\n",
    "        for enc in [\"utf-8\", \"latin1\"]:\n",
    "            try:\n",
    "                return pd.read_csv(path, encoding=enc)\n",
    "            except Exception:\n",
    "                pass\n",
    "        raise e\n",
    "\n",
    "trades_raw = load_table(hyperliquid_path)\n",
    "sent_raw   = load_table(feargreed_path)\n",
    "\n",
    "print(\"Trades shape:\", trades_raw.shape)\n",
    "print(\"Sentiment shape:\", sent_raw.shape)\n",
    "print(\"Trades columns:\", list(trades_raw.columns)[:20])\n",
    "print(\"Sent columns:\", list(sent_raw.columns))\n",
    "\n",
    "# --- Standardize column names ---\n",
    "trades = trades_raw.rename(columns={\n",
    "    \"execution price\": \"execution_price\",\n",
    "    \"start position\": \"start_position\",\n",
    "    \"closedPnL\": \"closedpnl\",\n",
    "    \"symbol\": \"symbol\",\n",
    "    \"account\": \"account\",\n",
    "    \"size\": \"size\",\n",
    "    \"side\": \"side\",\n",
    "    \"time\": \"time\",\n",
    "    \"event\": \"event\",\n",
    "    \"leverage\": \"leverage\"\n",
    "})\n",
    "sent = sent_raw.rename(columns={\n",
    "    \"Date\": \"date\",\n",
    "    \"Classification\": \"classification\",\n",
    "    \"classification\": \"classification\"\n",
    "})\n",
    "\n",
    "# --- Parse time/date ---\n",
    "# Trades time may be ms/seconds epoch or ISO string\n",
    "def to_datetime_safe(x):\n",
    "    try:\n",
    "        # numeric epoch?\n",
    "        if pd.api.types.is_number(x):\n",
    "            # Heuristic: treat > 10^12 as ms\n",
    "            if x > 1e12:\n",
    "                return pd.to_datetime(x, unit=\"ms\", utc=True)\n",
    "            else:\n",
    "                return pd.to_datetime(x, unit=\"s\", utc=True)\n",
    "        return pd.to_datetime(x, utc=True, errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "if \"time\" in trades.columns:\n",
    "    trades[\"time_dt\"] = trades[\"time\"].apply(to_datetime_safe)\n",
    "else:\n",
    "    # Try other names\n",
    "    for cand in [\"timestamp\", \"created_at\", \"executed_at\"]:\n",
    "        if cand in trades.columns:\n",
    "            trades[\"time_dt\"] = trades[cand].apply(to_datetime_safe)\n",
    "            break\n",
    "\n",
    "trades[\"date\"] = trades[\"time_dt\"].dt.tz_convert(\"UTC\").dt.date\n",
    "\n",
    "# Normalize types\n",
    "for col in [\"execution_price\", \"size\", \"leverage\", \"closedpnl\", \"start_position\"]:\n",
    "    if col in trades.columns:\n",
    "        trades[col] = pd.to_numeric(trades[col], errors=\"coerce\")\n",
    "\n",
    "# Clean 'side'\n",
    "if \"side\" in trades.columns:\n",
    "    trades[\"side\"] = trades[\"side\"].astype(str).str.strip().str.lower()\n",
    "    trades[\"side\"] = trades[\"side\"].replace({\"buy\":\"long\",\"sell\":\"short\"})\n",
    "    trades[\"side\"] = trades[\"side\"].where(trades[\"side\"].isin([\"long\",\"short\"]), other=\"unknown\")\n",
    "\n",
    "# Sentiment date parse\n",
    "if \"date\" in sent.columns:\n",
    "    sent[\"date\"] = pd.to_datetime(sent[\"date\"], errors=\"coerce\").dt.date\n",
    "\n",
    "# Sentiment label normalize\n",
    "if \"classification\" in sent.columns:\n",
    "    sent[\"classification\"] = sent[\"classification\"].astype(str).str.strip().str.title()\n",
    "    # Map to two classes where possible\n",
    "    sent[\"sent_bin\"] = sent[\"classification\"].map({\n",
    "        \"Fear\": \"Fear\",\n",
    "        \"Greed\": \"Greed\"\n",
    "    }).fillna(sent[\"classification\"])  # keep original if more granular\n",
    "else:\n",
    "    sent[\"sent_bin\"] = \"Unknown\"\n",
    "\n",
    "# Merge\n",
    "merged = pd.merge(trades, sent[[\"date\",\"sent_bin\",\"classification\"]].drop_duplicates(),\n",
    "                  on=\"date\", how=\"left\")\n",
    "\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "merged.to_csv(os.path.join(CSV_DIR, \"trades_merged.csv\"), index=False)\n",
    "print(\"Saved:\", os.path.join(CSV_DIR, \"trades_merged.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cf0a5b",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Feature Engineering\n",
    "Create per-trade metrics, leverage bands, win flag, ROI proxy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = merged.copy()\n",
    "\n",
    "# Win flag\n",
    "if \"closedpnl\" in df.columns:\n",
    "    df[\"win\"] = (df[\"closedpnl\"] > 0).astype(int)\n",
    "else:\n",
    "    df[\"win\"] = np.nan\n",
    "\n",
    "# Leverage bands\n",
    "if \"leverage\" in df.columns:\n",
    "    df[\"lev_band\"] = pd.cut(df[\"leverage\"], bins=[-np.inf, 2, 5, 10, 20, 50, np.inf],\n",
    "                            labels=[\"<=2x\",\"2–5x\",\"5–10x\",\"10–20x\",\"20–50x\",\">50x\"])\n",
    "\n",
    "# ROI proxy (approx): closedPnL / (abs(execution_price * size) / max(leverage,1))\n",
    "def roi_proxy(row):\n",
    "    ep = row.get(\"execution_price\", np.nan)\n",
    "    sz = row.get(\"size\", np.nan)\n",
    "    lev = row.get(\"leverage\", 1.0)\n",
    "    pnl = row.get(\"closedpnl\", np.nan)\n",
    "    if pd.isna(ep) or pd.isna(sz) or pd.isna(pnl):\n",
    "        return np.nan\n",
    "    denom = abs(ep * sz) / max(lev, 1.0)\n",
    "    return pnl / denom if denom not in [0, np.inf, -np.inf] else np.nan\n",
    "\n",
    "df[\"roi_proxy\"] = df.apply(roi_proxy, axis=1)\n",
    "\n",
    "# Save engineered\n",
    "df.to_csv(os.path.join(CSV_DIR, \"trades_engineered.csv\"), index=False)\n",
    "print(\"Saved:\", os.path.join(CSV_DIR, \"trades_engineered.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3918c5",
   "metadata": {},
   "source": [
    "\n",
    "## 4) EDA & Visuals\n",
    "All charts will be saved to `outputs/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e10fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_bar(series, title, fname):\n",
    "    plt.figure()\n",
    "    series.plot(kind=\"bar\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    path = os.path.join(OUT_DIR, fname)\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "    print(\"Saved chart:\", path)\n",
    "\n",
    "def save_boxplot(data, by_col, value_col, title, fname):\n",
    "    plt.figure()\n",
    "    data.boxplot(column=value_col, by=by_col)\n",
    "    plt.suptitle(\"\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    path = os.path.join(OUT_DIR, fname)\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "    print(\"Saved chart:\", path)\n",
    "\n",
    "# Trade counts by sentiment\n",
    "if \"sent_bin\" in df.columns:\n",
    "    counts = df[\"sent_bin\"].value_counts().sort_index()\n",
    "    counts.to_csv(os.path.join(CSV_DIR, \"counts_by_sentiment.csv\"))\n",
    "    save_bar(counts, \"Trade Counts by Sentiment\", \"counts_by_sentiment.png\")\n",
    "\n",
    "# Mean closedPnL by sentiment\n",
    "if \"closedpnl\" in df.columns and \"sent_bin\" in df.columns:\n",
    "    mean_pnl = df.groupby(\"sent_bin\")[\"closedpnl\"].mean().sort_index()\n",
    "    mean_pnl.to_csv(os.path.join(CSV_DIR, \"mean_pnl_by_sentiment.csv\"))\n",
    "    save_bar(mean_pnl, \"Mean closedPnL by Sentiment\", \"mean_pnl_by_sentiment.png\")\n",
    "    # Boxplot\n",
    "    save_boxplot(df.dropna(subset=[\"closedpnl\",\"sent_bin\"]), \"sent_bin\", \"closedpnl\",\n",
    "                 \"closedPnL Distribution by Sentiment\", \"box_closedpnl_by_sentiment.png\")\n",
    "\n",
    "# Win rate by sentiment × side × leverage band\n",
    "for group_cols, tag in [ ([\"sent_bin\"], \"sent\"),\n",
    "                         ([\"sent_bin\",\"side\"], \"sent_side\"),\n",
    "                         ([\"sent_bin\",\"lev_band\"], \"sent_lev\") ]:\n",
    "    if all(col in df.columns for col in group_cols):\n",
    "        agg = df.groupby(group_cols)[\"win\"].mean().reset_index().rename(columns={\"win\":\"win_rate\"})\n",
    "        agg.to_csv(os.path.join(CSV_DIR, f\"winrate_by_{tag}.csv\"), index=False)\n",
    "\n",
    "# Symbol × Sentiment mean ROI\n",
    "if all(col in df.columns for col in [\"symbol\",\"sent_bin\",\"roi_proxy\"]):\n",
    "    roi_pivot = df.pivot_table(index=\"symbol\", columns=\"sent_bin\", values=\"roi_proxy\", aggfunc=\"mean\")\n",
    "    roi_pivot.to_csv(os.path.join(CSV_DIR, \"roi_by_symbol_sentiment.csv\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c889198",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Statistical Tests\n",
    "Test differences between Fear vs Greed for PnL and win rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37481b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats_out = {}\n",
    "\n",
    "if \"sent_bin\" in df.columns:\n",
    "    fear = df.loc[df[\"sent_bin\"].str.contains(\"Fear\", case=False, na=False)]\n",
    "    greed = df.loc[df[\"sent_bin\"].str.contains(\"Greed\", case=False, na=False)]\n",
    "\n",
    "    # PnL comparison\n",
    "    if \"closedpnl\" in df.columns:\n",
    "        a = fear[\"closedpnl\"].dropna()\n",
    "        b = greed[\"closedpnl\"].dropna()\n",
    "        if len(a) > 5 and len(b) > 5:\n",
    "            # Non-parametric U-test\n",
    "            u_stat, p_val = stats.mannwhitneyu(a, b, alternative=\"two-sided\")\n",
    "            stats_out[\"p_closedpnl_mwu\"] = float(p_val)\n",
    "            stats_out[\"closedpnl_mean_fear\"] = float(a.mean())\n",
    "            stats_out[\"closedpnl_mean_greed\"] = float(b.mean())\n",
    "\n",
    "    # Win-rate comparison via chi-square\n",
    "    if \"win\" in df.columns:\n",
    "        win_fear = fear[\"win\"].dropna().astype(int)\n",
    "        win_greed = greed[\"win\"].dropna().astype(int)\n",
    "        if len(win_fear) > 5 and len(win_greed) > 5:\n",
    "            table = pd.crosstab(pd.concat([pd.Series([\"Fear\"]*len(win_fear)),\n",
    "                                           pd.Series([\"Greed\"]*len(win_greed))], ignore_index=True),\n",
    "                                pd.concat([win_fear, win_greed], ignore_index=True))\n",
    "            chi2, p, dof, exp = stats.chi2_contingency(table)\n",
    "            stats_out[\"p_winrate_chi2\"] = float(p)\n",
    "            stats_out[\"winrate_fear\"] = float(win_fear.mean())\n",
    "            stats_out[\"winrate_greed\"] = float(win_greed.mean())\n",
    "\n",
    "pd.DataFrame([stats_out]).to_csv(os.path.join(CSV_DIR, \"stat_tests_summary.csv\"), index=False)\n",
    "print(\"Saved stats summary:\", os.path.join(CSV_DIR, \"stat_tests_summary.csv\"))\n",
    "stats_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2429888b",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Predictive Modeling (Logistic Regression)\n",
    "Predict `win` using sentiment, side, leverage, symbol, and size. This is a baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_metrics = {}\n",
    "work = df.dropna(subset=[\"win\"]).copy()\n",
    "\n",
    "# Feature set\n",
    "cat_cols = [c for c in [\"sent_bin\",\"side\",\"symbol\"] if c in work.columns]\n",
    "num_cols = [c for c in [\"leverage\",\"size\",\"roi_proxy\",\"execution_price\"] if c in work.columns]\n",
    "\n",
    "# One-hot encode categoricals\n",
    "enc = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "X_cat = enc.fit_transform(work[cat_cols]) if cat_cols else np.empty((len(work),0))\n",
    "X_num = work[num_cols].fillna(0).to_numpy() if num_cols else np.empty((len(work),0))\n",
    "X = np.hstack([X_cat, X_num])\n",
    "y = work[\"win\"].astype(int).to_numpy()\n",
    "\n",
    "# Train/test split\n",
    "if len(work) > 100:\n",
    "    test_size = 0.2\n",
    "else:\n",
    "    test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "# Model\n",
    "clf = LogisticRegression(max_iter=200, n_jobs=None)\n",
    "clf.fit(X_train, y_train)\n",
    "proba = clf.predict_proba(X_test)[:,1]\n",
    "preds = (proba >= 0.5).astype(int)\n",
    "\n",
    "# Metrics\n",
    "auc = roc_auc_score(y_test, proba)\n",
    "report = classification_report(y_test, preds, output_dict=True)\n",
    "cm = confusion_matrix(y_test, preds).tolist()\n",
    "\n",
    "model_metrics = {\n",
    "    \"auc\": float(auc),\n",
    "    \"accuracy\": float(report[\"accuracy\"]),\n",
    "    \"precision_1\": float(report.get(\"1\", {}).get(\"precision\", np.nan)),\n",
    "    \"recall_1\": float(report.get(\"1\", {}).get(\"recall\", np.nan)),\n",
    "    \"cm\": cm\n",
    "}\n",
    "\n",
    "pd.DataFrame([model_metrics]).to_csv(os.path.join(CSV_DIR, \"model_metrics.csv\"), index=False)\n",
    "print(\"Saved:\", os.path.join(CSV_DIR, \"model_metrics.csv\"))\n",
    "model_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84620e76",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Auto‑Summary Draft\n",
    "Creates a draft insights file from current results. You can refine wording in the PDF report.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059166d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lines = []\n",
    "def fmt(x): \n",
    "    try:\n",
    "        return f\"{x:.4f}\"\n",
    "    except Exception:\n",
    "        return str(x)\n",
    "\n",
    "# Pull aggregates if they exist\n",
    "try:\n",
    "    mean_pnl = pd.read_csv(os.path.join(CSV_DIR, \"mean_pnl_by_sentiment.csv\"), index_col=0).iloc[:,0].to_dict()\n",
    "except Exception:\n",
    "    mean_pnl = {}\n",
    "\n",
    "try:\n",
    "    stats_summary = pd.read_csv(os.path.join(CSV_DIR, \"stat_tests_summary.csv\")).iloc[0].to_dict()\n",
    "except Exception:\n",
    "    stats_summary = {}\n",
    "\n",
    "try:\n",
    "    model_summary = pd.read_csv(os.path.join(CSV_DIR, \"model_metrics.csv\")).iloc[0].to_dict()\n",
    "except Exception:\n",
    "    model_summary = {}\n",
    "\n",
    "lines.append(\"Key Findings:\")\n",
    "if mean_pnl:\n",
    "    lines.append(f\"- Mean closedPnL: { {k: fmt(v) for k,v in mean_pnl.items()} }\")\n",
    "if stats_summary:\n",
    "    if \"p_closedpnl_mwu\" in stats_summary:\n",
    "        lines.append(f\"- PnL difference Fear vs Greed p-value (Mann-Whitney U): {fmt(stats_summary['p_closedpnl_mwu'])}\")\n",
    "    if \"p_winrate_chi2\" in stats_summary:\n",
    "        lines.append(f\"- Win-rate difference Fear vs Greed p-value (Chi-square): {fmt(stats_summary['p_winrate_chi2'])}\")\n",
    "    if \"winrate_fear\" in stats_summary and \"winrate_greed\" in stats_summary:\n",
    "        lines.append(f\"- Win-rate Fear={fmt(stats_summary['winrate_fear'])}, Greed={fmt(stats_summary['winrate_greed'])}\")\n",
    "if model_summary:\n",
    "    lines.append(f\"- Logistic baseline AUC={fmt(model_summary.get('auc'))}, Accuracy={fmt(model_summary.get('accuracy'))}\")\n",
    "\n",
    "lines.append(\"Recommendations:\")\n",
    "lines.append(\"- Consider reducing leverage during Fear days, especially if loss odds significantly increase.\")\n",
    "lines.append(\"- Focus on symbols and sides that historically perform better under each sentiment regime.\")\n",
    "lines.append(\"- Use sentiment-aware position sizing and tighter risk controls on adverse regimes.\")\n",
    "\n",
    "insight_path = os.path.join(OUT_DIR, \"insights_draft.txt\")\n",
    "with open(insight_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "print(\"Saved:\", insight_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3423282d",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Create the Final PDF\n",
    "- Open `ds_report_template.md`, paste in the insights and insert saved charts from `outputs/`.\n",
    "- In Colab: **File → Print → Save as PDF** (or copy to Google Docs → File → Download → PDF).\n",
    "- Name the final file `ds_report.pdf` and place it in the project root.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
